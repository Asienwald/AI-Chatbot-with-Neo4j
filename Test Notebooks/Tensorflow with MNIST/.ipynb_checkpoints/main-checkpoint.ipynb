{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='cyan'>Tensorflow with MNIST</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greyscale visualisation of the RGB codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "image_index = 7777 # can select anything up to 60000\n",
    "print(y_train[image_index]) # label is 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc8f9a12208>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[image_index], cmap='Greys') # greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "# 60000 = number of images in train dataset\n",
    "# (28, 28) = size of the image (in pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping & Normalising the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo use dataset in Keras API, need 4-dims numpy arrays\\nHowever, our arrays is 3-dims\\n\\nHence must normalise our data as required in neurel network models\\nCan achieve this by dividing RGB codes to 255\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "To use dataset in Keras API, need 4-dims numpy arrays\n",
    "However, our arrays is 3-dims\n",
    "\n",
    "Hence must normalise our data as required in neurel network models\n",
    "Can achieve this by dividing RGB codes to 255\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Reshape array to 4-dims so can work with Keras\n",
    "print(x_train.shape[0]) # the size of train data\n",
    "print(x_test.shape[0])\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Making sure that values are float so we can get decimal\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "print(x_train.shape) # no change but its good coding practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train: 60000\n"
     ]
    }
   ],
   "source": [
    "# normalising the RGB codes by dividing it into max RGB value\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"Number of images in x_train: {x_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dropout layers fight with the overfitting by disregarding some neurons\n",
    "while training\n",
    "\n",
    "Flatten layers flatten 2D arrays to 1D array before building fully\n",
    "connected layers\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import required Keras modules containing model & layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model & add the layers\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(28, kernel_size = (3, 3), input_shape = input_shape))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Flatten the 2D arrays for fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# can experiment with params in 1st Dense layer to get better results\n",
    "# kernel size, pool size, activation functions, dropout rate, no. neurons etc\n",
    "model.add(Dense(128, activation = tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 10 neurons since have 10 number class for last layer\n",
    "model.add(Dense(10, activation = tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling & Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAbove we created non-optimised empty CNN\\nNow set an optimiser with a given loss function which uses a metric\\nThe fit the model by using our train data\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Above we created non-optimised empty CNN\n",
    "Now set an optimiser with a given loss function which uses a metric\n",
    "The fit the model by using our train data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.2167 - accuracy: 0.9352\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.0848 - accuracy: 0.9746\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0592 - accuracy: 0.9815\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.0451 - accuracy: 0.9853\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.0346 - accuracy: 0.9885\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.0281 - accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.0244 - accuracy: 0.9915\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 0.0214 - accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0190 - accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0185 - accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc8e101c9e8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adam optimiser usually out performs other optimisers\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(x = x_train, y = y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 61us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.056662386979447, 0.9846000075340271]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model with x_test & y_test\n",
    "model.evaluate(x_test, y_test)\n",
    "# achieved 98.5% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Can also make individual predictions with following code\n",
    "image_index = 4444\n",
    "plt.imshow(x_test[image_index].reshape(28, 28), cmap = 'Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())\n",
    "# model classified image as 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yay!\n",
    "- successfully written convolutional neural network to classify\n",
    "  handwritten digits with Tensorflow's Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
